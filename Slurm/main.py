#! /usr/bin/env python
import os
import time
import yaml
import pdb
import argparse
from ConfigSpace import Categorical, ConfigurationSpace, Float
from ConfigSpace.conditions import InCondition
from smac import HyperparameterOptimizationFacade, Scenario
from scipy.stats import gmean
from utilities import run_python_slurm_job, get_filename, remove_slurm_files, str_to_bool, is_dir
from parameters import *


class CutSelectorTuner:

    def __init__(self, seed, instance_dir, solution_dir, results_dir, outfiles_dir):
        self.seed = seed
        self.instance_dir = instance_dir
        self.solution_dir = solution_dir
        self.results_dir = results_dir
        self.outfiles_dir = outfiles_dir
        assert os.path.isdir(results_dir)
        assert os.path.isdir(outfiles_dir)

    @property
    def configspace(self) -> ConfigurationSpace:
        """
        Function for defining the ConfigurationSpace.

        Returns:
            The configuration space that will be sampled from
        """

        # Build Configuration Space that defines all parameters and their ranges
        cs = ConfigurationSpace(seed=self.seed)

        # Create the hyperparameters
        isp_weight = Float("isp", (0.0, 1.0), default=0.1, meta={"instance_dir": self.instance_dir,
                                                                 "solution_dir": self.solution_dir,
                                                                 "results_dir": self.results_dir,
                                                                 "outfiles_dir": self.outfiles_dir})
        obp_weight = Float("obp", (0.0, 1.0), default=0.1)
        eff_weight = Float("eff", (0.0, 1.0), default=1.0)
        exp_weight = Float("exp", (0.0, 1.0), default=0.1)
        psc_weight = Float("psc", (0.0, 1.0), default=0.1)
        loc_weight = Float("loc", (0.0, 1.0), default=0.1)
        sparsity_bonus = Float("sparsity_bonus", (0.0, 1.0), default=0.1)
        end_sparsity_bonus = Float("end_sparsity_bonus", (0.0, 1.0), default=0.4)
        max_non_zero_root_budget = Float("root_budget", (0.0, 10.0), default=2.5)
        max_non_zero_tree_budget = Float("tree_budget", (0.0, 10.0), default=1.5)
        max_parallel = Float("max_parallel", (0.01, 1), default=0.9)
        parallel_penalty = Float("parallel_penalty", (0.0, 0.5), default=0.2)
        max_density = Float("max_density", (0.05, 1.0), default=0.4)
        filter_dense_cuts = Categorical("filter_dense_cuts", [True, False], default=False)
        filter_parallel_cuts = Categorical("filter_parallel_cuts", [True, False], default=True)
        penalise_locks = Categorical("penalise_locks", [True, False], default=False)
        penalise_obp = Categorical("penalise_obp", [True, False], default=False)

        # Then create the dependencies
        penalise_instead_of_filter = InCondition(child=parallel_penalty, parent=filter_parallel_cuts, values=[False])
        sample_max_density = InCondition(child=max_density, parent=filter_dense_cuts, values=[True])

        # Add the hyperparameters and conditions to our configspace
        cs.add_hyperparameters([isp_weight, obp_weight, eff_weight, exp_weight,
                                psc_weight, loc_weight, sparsity_bonus, end_sparsity_bonus,
                                max_non_zero_root_budget, max_non_zero_tree_budget, max_parallel,
                                parallel_penalty, max_density, filter_dense_cuts,
                                filter_parallel_cuts, penalise_locks, penalise_obp])

        cs.add_conditions([penalise_instead_of_filter, sample_max_density])

        return cs

    @staticmethod
    def train(config, seed) -> float:
        """
        The main function for training. This function will be given a configuration, and then issue all
        SLURM jobs such that the runs gets solved using those parameters. The results from the run are then loaded,
        compared to that of default runs, and a value is return (ratio of geometric means for time. smaller is better)
        Args:
            config (Configuration): The configuration object containing all information on the run
            seed (int): Random seed (useless as we do deterministic runs) # TODO: Figure out how to remove

        Returns:
            ratio of geometric means for solve time (sample from config space vs default SCIP)
        """

        # Run all instances in training set using the hyperparameter values generated by SMAC.
        # Return a sum of time / nodes / iterations (which SMAC will aim to minimise)
        config_dict = config.get_dictionary()
        # Now make a list of the stuff to pass to solve_instance
        config_list = []

        # Extract the results and outfiles directory we buried in the meta dictionary
        instance_dir = config.configuration_space["isp"].meta["instance_dir"]
        solution_dir = config.configuration_space["isp"].meta["solution_dir"]
        results_dir = config.configuration_space["isp"].meta["results_dir"]
        outfiles_dir = config.configuration_space["isp"].meta["outfiles_dir"]

        for hyperparameter in ["isp", "obp", "eff", "exp", "psc", "loc", "sparsity_bonus", "end_sparsity_bonus",
                               "root_budget", "tree_budget", "max_parallel", "parallel_penalty", "max_density",
                               "filter_dense_cuts", "filter_parallel_cuts", "penalise_locks",
                               "penalise_obp"]:
            if hyperparameter in config_dict:
                config_list.append(config_dict[hyperparameter])
            else:
                assert hyperparameter in ["parallel_penalty", "max_density"]
                if hyperparameter in ["max_density"]:
                    config_list.append(1.0)
                else:
                    config_list.append(0.0)

        # Create the results and outfile directory for this SMAC run
        for cut_dir in [results_dir, outfiles_dir]:
            if os.path.isdir(cut_dir):
                remove_slurm_files(cut_dir)
            else:
                os.mkdir(cut_dir)

        # Get all the instance paths TODO: Figure out a nice way to pass this information to SMAC
        instance_paths = [os.path.join(instance_dir, file) for file in os.listdir(instance_dir)]
        instances = [path.split('/')[-1].split('.mps')[0] for path in instance_paths]
        solution_paths = [os.path.join(solution_dir, instance + ".sol.gz") for instance in instances]

        # Iterate over all random seed and permutation seed combinations
        slurm_job_ids = []
        scip_time_lim = MAX_MULTIPLE_DEFAULT_RUN_TIME * TRAINING_SET_TIME_LIMIT_WITH_SOLUTION
        for p in PERMUTATION_SEEDS:
            for r in RANDOM_SEEDS:
                for i, instance in enumerate(instances):
                    ji = run_python_slurm_job(python_file='Slurm/solve_instance.py',
                                              job_name='{}--{}--{}'.format(instance, r, p),
                                              outfile=os.path.join(outfiles_dir, '%j__{}__{}__{}.out'.format(
                                                  instance, r, p)),
                                              time_limit=scip_time_lim + 20,
                                              arg_list=[results_dir, instance_paths[i], instance, r,
                                                        p, scip_time_lim, True, None,
                                                        solution_paths[i], False] + config_list
                                              )
                    slurm_job_ids.append(ji)

        # Wait for the jobs to finish
        wait_for_jobs_to_finish(slurm_job_ids, outfiles_dir)

        # Now read the results.
        default_times = []
        run_times = []
        default_nodes = []
        run_nodes = []
        for p in PERMUTATION_SEEDS:
            for r in RANDOM_SEEDS:
                for i, instance in enumerate(instances):
                    yml_file = get_filename(results_dir, instance, r, p, ext='yml')
                    if os.path.isfile(yml_file):
                        with open(yml_file, 'r') as s:
                            yml_data = yaml.safe_load(s)
                        with open(get_filename(SMAC_DEFAULT_RESULTS_DIR, instance, r, p, ext='yml'), 'r') as s:
                            default_data = yaml.safe_load(s)
                        if yml_data['status'] == 'timelimit':
                            default_times.append(default_data['solve_time'] + 1)
                            default_nodes.append(default_data['num_nodes'] + 10)
                            run_times.append(scip_time_lim)
                            default_nodes.append(MAX_MULTIPLE_DEFAULT_RUN_TIME * default_data['num_nodes'])
                        elif yml_data['status'] == 'optimal':
                            default_times.append(default_data['solve_time'] + 1)
                            default_nodes.append(default_data['num_nodes'] + 10)
                            run_times.append(yml_data['solve_time'] + 1)
                            run_nodes.append(yml_data['num_nodes'] + 10)
                        else:
                            print('Instance {} p {} r {} status {}!'.format(
                                instance, p, r, yml_data['status']), flush=True)
                    else:
                        print('Instance {} p {} r {} failed!'.format(instance, p, r), flush=True)

        # Get the relative geometric means of all the different measures
        time_improvement = (gmean(run_times) - 1) / (gmean(default_times) - 1)
        node_improvement = (gmean(run_nodes) - 10) / (gmean(default_nodes) - 10)

        # Sum up the measures (smaller value is better)
        # print('Config: {}'.format(config), flush=True)
        print('Time: {}. Nodes: {}'.format(time_improvement, node_improvement), flush=True)
        return time_improvement


def generate_default_run_data(instance_dir, solution_dir, outfiles_dir, results_dir):
    """
    Function for generating default run data that SMAC will compare against at every iteration
    Args:
        instance_dir (dir): Directory where all instances are contained
        solution_dir (dir): Directory where all solution files are contained
        outfiles_dir (dir): Directory where all outfiles for this default run will be dropped
        results_dir (dir): Directory where all result files for this default run will be dropped

    Returns:

    """

    # Remove previous default runs
    remove_slurm_files(outfiles_dir)
    remove_slurm_files(results_dir)

    # Get all the instance paths
    instance_paths = [os.path.join(instance_dir, file) for file in os.listdir(instance_dir)]

    # Issue all the jobs
    slurm_job_ids = []
    for p in PERMUTATION_SEEDS:
        for r in RANDOM_SEEDS:
            for i, instance_path in enumerate(instance_paths):
                instance = instance_path.split('/')[-1].split(".mps")[0]
                solution_path = os.path.join(solution_dir, instance + ".sol.gz")
                ji = run_python_slurm_job(python_file='Slurm/solve_instance.py',
                                          job_name='{}--{}--{}'.format(instance, r, p),
                                          outfile=os.path.join(outfiles_dir, '%j__{}__{}__{}.out'.format(
                                              instance, r, p)),
                                          time_limit=2*TRAINING_SET_TIME_LIMIT_WITH_SOLUTION,
                                          arg_list=[results_dir, instance_paths[i], instance, r,
                                                    p, TRAINING_SET_TIME_LIMIT_WITH_SOLUTION, True, None,
                                                    solution_path, True, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
                                                    0.0, 1.0, 1, 1, 1.0, 0.2, 0.4, False, True, False, False]
                                          )
                slurm_job_ids.append(ji)

    # Wait for the jobs to finish
    wait_for_jobs_to_finish(slurm_job_ids, outfiles_dir)


def wait_for_jobs_to_finish(slurm_job_ids, outfiles_dir):
    """
    Put everything to sleep until all SLURM jobs are complete
    Args:
        slurm_job_ids (dir): The IDs of submitted SLURM jobs we need to wait on
        outfiles_dir (dir): Where to output our completion file

    Returns:
        Nothing. Will just resume when all issued SLURM JOBS are complete
    """

    # Now submit the checker job that has dependencies slurm_job_ids
    safety_file_no_ext = os.path.join(outfiles_dir, 'safety_check')
    _ = run_python_slurm_job(python_file='Slurm/safety_check.py',
                             job_name='cleaner',
                             outfile=safety_file_no_ext + '.out',
                             time_limit=10,
                             arg_list=[safety_file_no_ext + '.txt'],
                             dependencies=slurm_job_ids)
    # Put the program to sleep until all of slurm jobs are complete
    time.sleep(5)
    while not os.path.isfile(safety_file_no_ext + '.txt'):
        time.sleep(5)

    return


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('generate_default_runs', type=str_to_bool)
    parser.add_argument('seed', type=int)
    parser.add_argument('instance_dir', type=is_dir)
    parser.add_argument('solution_dir', type=is_dir)
    parser.add_argument('results_dir', type=is_dir)
    parser.add_argument('outfiles_dir', type=is_dir)
    args = parser.parse_args()

    # Generate default runs if requested
    if args.generate_default_runs:
        generate_default_run_data(args.instance_dir, args.results_dir, SMAC_DEFAULT_OUTFILES_DIR,
                                  SMAC_DEFAULT_RESULTS_DIR)

    # Load the CutSelectorTuner
    classifier = CutSelectorTuner(args.seed, args.instance_dir, args.solution_dir, args.results_dir, args.outfiles_dir)

    # Next, we create an object, holding general information about the run
    scenario = Scenario(
        classifier.configspace,
        deterministic=True,
        n_trials=300,  # Total number of trials we can run
        n_workers=1,
        seed=args.seed
    )

    # We want to run some random configurations before starting the optimization.
    initial_design = HyperparameterOptimizationFacade.get_initial_design(scenario, n_configs=170, max_ratio=0.9)

    # Now we use SMAC to find the best hyperparameters
    smac = HyperparameterOptimizationFacade(
        scenario,
        classifier.train,
        initial_design=initial_design,
        overwrite=True,  # If the run exists, we overwrite it; alternatively, we can continue from last state
    )

    # Start optimising!
    incumbent = smac.optimize()

    # Print what the best parameters were
    print('The Best Parameter Choices: {}'.format(incumbent))
    print('Results saved to dir: {}'.format(smac.scenario.output_directory))
    # # Get cost of the incumbent (best) configuration
    incumbent_cost = smac.validate(incumbent)
    print('Incumbent Cost: {}'.format(incumbent_cost), flush=True)
